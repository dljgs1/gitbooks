快速生成第一阶段候选级联Rankers

## 摘要

当前的搜索引擎都有基于数百个特征的复杂的评价函数。这种评价函数要能够返回高质量的结果，这在评价所有文档的过程中产生了效率挑战。为了解决这个问题，搜索引擎使用了一系列级联的评价器，从非常简单的排序函数开始，不断在更小的候选集合上应用复杂和高开销的函数。最近的研究者开始研究这个框架下处理级联排序器的一些问题，如5，13，17，51。。

我们关注初始级联设计的问题。因此目标就是快速地识别出一系列好的候选文档用于推到更后层。Asadi和Lin之前的工作展示了一个top-k的计算能给出


目前的搜索引擎使用基于数百个功能的非常复杂的排名功能。尽管这样的功能会返回高质量的结果，但它们会带来效率方面的挑战，因为在工会中的所有文档（甚至是查询条件的交叉点）上对其进行全面评估的成本太高。为了解决这个问题，搜索引擎使用一系列级联的rankers，从一个非常简单的排名函数开始，然后将越来越复杂和昂贵的排名函数应用在越来越小的候选结果集上。研究人员最近开始研究在级联rankers的查询处理框架中的几个问题;参见例如[5,13,​​17,51]。

我们关注一个这样的问题，即初始级联的设计。因此，我们的目标是要很快确定一系列应该传递给第二级和更高级的候选文件。 Asadi和Lin [3，5]的前期工作表明，虽然在联合或交叉点上进行top-k计算可以获得好的结果，但是使用基于垃圾邮件分数的全球文档排序的进一步优化会导致质量显着降低。我们的贡献是提出一个替代框架，建立专门的单项和成对索引结构，然后在查询期间有选择地访问这些结构的成本预算和一套早期终止技术。通过使用复杂的机器级别排序器进行端到端评估，我们发现，我们的方法发现候选者的速度比联合top-k计算快一个数量级，而本质上匹配质量。

## 引言

搜索引擎不断优化他们的排名功能，以提高结果质量。这通常是通过越来越复杂的排名功能来实现的，这些功能基于大量的功能，包括通过文本，链接结构，过去的查询以及通过各种数据提取和挖掘技术的在线或专有数据集和知识库。但是，这些复杂的排名功能会对引擎造成严重的性能挑战，因为在大量文档上评估它们非常昂贵。考虑到每天必须处理的数十亿个查询，即使在连接的情况下，将这些函数直接应用于通过初始布尔过滤器的所有文档也是不可行的。

为了应对这一挑战，目前所有的主要引擎似乎都采用级联的方法来查询处理，通过一系列日益复杂的中间函数来近似这些排序函数的结果。因此，在查询分析和重写之后，搜索引擎首先应用非常简单的排序函数，类似于BM25或余弦测度，其仅使用少量特征并且可以非常有效地应用于大量候选者。我们把这个过程称为第一个级联。接下来，在第二级联中，基于更大特征的更复杂的函数被应用于例如来自第一级联的前几千个结果。在第三和更高的级联中，更复杂的功能被应用于前几个级联的更小和更小的存留候选者。这种方法在[51]中被描述和形式化。因此，级联方法的目标是返回（几乎）与在所有候选项上应用复数函数所得到的结果相同的结果，这只是计算成本的一小部分。然而，其适当的实施却带来了一些近来在文献中引起注意的挑战[5,13,​​17,32,40,51]。尤其是，工作集中在四个不同的挑战上：

（1）如何设计日益复杂的排序功能和相关截止点的良好序列（保留下一个级联的结果数量）[51]; 

（2）如何利用早期退出策略有效地将复杂的排序功能应用于候选人[13]; 

（3）如何设计第一个级联的排名函数，以保留后续级联的许多优秀候选人，而不是关注如何排序几个最重要的结果[17]; 

（4）如何通过布尔过滤器和各种早期终止技术的最优选择有效地实现第一个级联[3，5]。

我们把重点放在最后的挑战上，这是重要的，因为第一个级联是对大量候选人执行的。在[3，5]中的结果表明，对于第一级联，联合滤波器基本上和分离滤波器一样好，同时节省了大量的时间。然而，使用全局文档命令避免索引结构的完全连贯遍历的天真尝试导致了端到端结果质量的显着损失。

在本文中，我们提出了一种方法，其运行速度比甚至高度优化的连续和分离式top-k计算快一个数量级，同时实现基本相同的端到端结果质量。更确切地说，给定一个复杂的排序函数需要通过级联方法进行近似，一个文档集合的倒排索引结构和一个训练查询轨迹，我们将演示如何构建索引结构的辅助层，以及如何选择部分这一层咨询提交的查询，以获得有限的计算和空间预算的高质量候选。


具体来说，我们的贡献如下：

1.我们设计一个框架，建立受特定空间约束的专门化的单项和成对指数结构。它使用有限的查询轨迹来训练查询词语言模型和发布质量模型。 

2.我们提出了一种基于成本预算的在线选择算法，针对给定查询，根据发布质量模型确定每个可用结构的访问深度，并提出进一步提高性能的查询处理和查找策略。 

3.我们提供了ClueWeb09B上我们建议的体系结构的端到端评估，并表明我们的方法可以比以前发布的结果更快地识别候选项，质量损失可以忽略不计。

本文的其余部分安排如下：第2节介绍一些背景，并讨论相关工作。在第3部分中，我们对我们的方法进行了高度概括，并提供了针对多个组件的解决方案。接下来，第4节概述了实验设置，第5节提出了对拟议框架的实验评估。最后，第6节提供了一些结论性意见。

## 2 背景和相关工作

在本节中，我们提供一些关于倒排索引，查询处理和提前终止技术以及级联排名架构的背景知识，并讨论相关工作。

#### 倒排索引
商业搜索引擎基于广泛使用的倒排索引执行查询处理[58]。给定N个文档的集合，为每个文档分配一个从0到N-1的唯一标识符（docID）。倒排索引由一组倒排和词典组成。特别地，对于集合中的每个不同的术语t，都有一个倒列表Lt。每个Lt是指定出现的文档的发布列表。通常，每个发布包含包含t的文档的docID和频率t在文档中;但是，也可能有其他信息，例如文档中出现的词项的位置，或预先计算的影响分数。词典包含集合中的每个唯一词项指向相应的反转列表的指针。反向索引压缩对于搜索引擎性能至关重要，许多技术已经被提出[6,45]。

#### 索引布局
组织倒排列表有很多种方法。在文档排序的索引中，每个列表按docID排序，导致连续docID之间的小差距（d-gap），导致压缩大小更小[45]。影响排序的索引按照影响分数的降序对每个列表中的发布进行排序。因此，得分高的查询结果往往位于列表的前面，可能使智能查询处理算法跳过列表的其余大部分。但是，与文档排序的索引相比，这种方法导致可压缩性差，并且可能需要对docID进行随机查找，docID在一个查询词上得分较高，而在其他词上得分较低。最后，影响分层索引根据影响分数将每个倒排列表分成少数几个层次。我们的方法使用两层，其中第一层高影响力的帖子按影响排序，第二层用docID进行排序，以允许高效的随机查找。

#### 索引遍历
在查询处理过程中，可以通过不同的方式遍历索引结构[50]。在Documentat-a-time（一次一篇遍历文章DAAT）中，每个列表都有一个指向当前发布的指针，并且一次处理一个文档。那么指针在docID空间中向前移动。最好的结果通常保持在最小堆结构中。在一次Term-at-a-time（一次遍历一个词项TAAT）遍历中，在访问下一个列表之前，完全遍历一个列表。部分计分的文件作为累加器保存在散列表或其他结构中;如果它超出了CPU缓存的范围，这个结构可能会成为一个瓶颈。最后，DAAT和TAAT之间还有交集。请注意，DAAT主要适用于文档排序的索引，而TAAT适用于影响排序的索引。


### 2.1 查询处理和提前终止

最简单的查询处理形式在查询条件的倒排列表上应用布尔过滤器（AND / OR），然后对通过过滤器的所有文档进行排序。一个好的排名函数应该（a）提供文档与查询相关性的良好近似，和（b）使用存储在索引中的信息可以有效地计算。众所周知的例子包括余弦测量和BM25 [6]。这些简单的排序方案中的大多数具有如下性质：对于完整查询q，文档d的得分是每项得分的总和（或其他简单组合）即，score（q，d）= ∑(t∈q) s（t，d），其中s（t，d）是d中的项t的影响分数。

#### 提前终止
一个简单的查询处理方法是效率低下，并最终解压缩和访问大部分倒排列表。为了改善这一点，研究人员提出了许多早期终止（ET）算法，试图找到好的结果，而访问和评分只有一小部分相关的倒排列表。如果ET算法总是返回与穷举算法相同的结果，则算法是安全的，否则就不安全[48]。 ET技术广泛应用于商业引擎和学术系统，包括以下方法：
- 索引分层：集合被分割成2或3个不相交的文档子集，称为分层，其中第一层包含最高质量文件;查询在第一层上执行，只有选择性地路由到其他层[41,42]。 
- 修剪：在静态修剪中，从索引中删除被认为不太有用的帖子[8,12,24,37]。在动态修剪中，倒排列表通常以影响排序或影响分层的形式进行组织，算法侧重于高影响力的发布，而只选择性地访问有前途的文档的影响力较小的发布。一个被广泛研究的例子是[23]中的FA，TA和NRA算法。 
- 跳过：对于文档排序的索引，有不同的技术可以跳过倒排列表中不重要的部分[10,14,19,20,21]。

我们的方法是不安全的，基于动态修剪和冲击层结构术语和术语对（两项的交点），如后面所述。

### 2.2级联架构

在现代商业引擎中，查询处理基于级联排名方案[10,13,51]，其中每个级联包括提供候选文档到后续级联的排序器。第一个级联通常是基于一个非常简单的排名函数，该函数在索引结构的大部分上进行评估，以获得最初的一组候选人。因此，这个功能必须非常快，同时提供相当高质量的候选人。随后的级联使用更复杂和更昂贵的排名函数对更少的候选人执行。设计这种级联架构的挑战是选择一组级联和相关联的排名函数，以低成本实现高端到端质量。

级联设置对于现代商用发动机的性能和质量是至关重要的，最近许多论文集中在这个设置上[4,5,13,​​17,32,40,51]。我们专注于优化这种架构中第一个级联的效率，这是最近研究的一个问题[4,5]。


### 2.3 与前人工作的对比

我们现在讨论我们的方法与以前的工作的关系。我们考虑的特定问题是基于[5，4，17]中的设置。因此，我们有一个两阶段级联架构，第一阶段获得数百或数千文档的初始候选集，而第二阶段则使用基于数十或数百个特征的更复杂的排序器重新排列这些候选者。我们的目标是为第一阶段设计非常快速的ET算法，实现端到端的质量与更详尽的方法相媲美。这基本上是Asadi和Lin在[4，5]中提到的问题。

特别是，[5]调查了各种第一阶段候选生成方法的效率/有效性权衡。他们尝试了连接WAND [10]，析取WAND和两个连接算法，首先获得交集，然后根据BM25或垃圾邮件分数重新排列结果，并得出结论WAND提供了最佳的折衷。在[4]中的工作展示了如何使用布隆过滤器来加速基于交集的方法。我们在这里的贡献是提供一种方法，以较低的成本实现与其最佳方法相媲美的质量。

另一个相关的近期工作[52]提出了文件选择性评估方法，以在第一个级联中实现更好的效率/效率平衡。在[52]中报告的运行时间比我们的要慢得多，尽管有些想法可能会被用来进一步优化我们的方法的查找阶段。

我们的算法基于分层索引组织，对受影响排序的单一和术语对结构执行有限的深度访问，随后进行随机查找。因此，它与Fagin [23]提出的众所周知的FA算法以及[39]中引入的影响分层指标的ET算法密切相关。随后有许多论文进一步发展并经常结合这些方法来解决各种IR排序问题，包括例如[2,7,9,33,47,48]。

我们注意到[28,29]描述了数据库应用程序中top-k查询处理的许多访问和查找策略。一种与我们的方法有点相似的算法是文献[28]中的MPro算法，该算法通过排序访问寻求最小化查找成本。在[48]中提出了将访问深度选择到可用的单一影响排序列表中的建议方法。然而，[48]只关注单项影响排序列表，并没有提供在级联ranker的上下文中基于成本的查询处理算法。我们的方法与上述两者不同，因为我们提出了基于查询词分布和发布质量模型并受空间限制的构建额外影响排序索引结构（包括配对结构）的框架，以及在线深度选择算法和查找策略。

我们的方法很大程度上依赖于[34]中引入的术语对索引结构，随后在[11,15,26,30,44,54,56,57]等多篇论文中进行了研究。我们的工作与[30]关系最密切，也将[23]中的方法应用于配对结构。主要区别在于我们关注级联排名方案，以及基于有限的空间和访问成本预算来优化索引结构和索引遍历的框架。同样相关的是[11]中的工作，该工作提出了在查询处理过程中完成单个和成对碰撞排序的列表的构建。

虽然相关，但我们的工作有两个不同的方面：虽然[11]和[44,54,56,57]早期的工作假定排序功能，直接考虑接近，我们假设在一个级联设置更复杂的功能。此外，[11]中所得到的辅助结构远大于基本指数大小;相比之下，我们的查询语言和发布质量模型使我们能够实现高速，只有有限的增长。我们注意到，如[11,54]所做的那样，我们的结果可能通过在文档中添加特殊的成对结构来相互靠近。

最后，[1,27]给出了一系列文档和查询来学习更好的索引结构的学习技巧。特别地，[27]可以被看作本质上是学习索引发布的顺序，比在[23]中使用的“自然”基于影响的顺序更好。我们注意到这个问题与我们的方法是正交的，并且可以结合起来以产生额外的好处。最后，虽然我们使用离线预处理来构建第一层结构，但也可以通过合适的缓存机制来解决这个问题，比如[25,38,46]中的其他类型的结构。最后，我们的改进除了通过结果缓存实现的任何加速之外，因为我们的查询跟踪没有大量的重复查询。


## 3 问题设定和方法

我们现在定义和讨论我们的问题设置，对我们的方法进行高级描述，然后提供有关涉及的各个步骤的更多详细信息。 

### 3.1 问题的建立

我们给出了一个复杂的排序函数CF，一个简单的排名函数SF用作第一个级联，以及一个排名截止c用于第一个级联，这意味着只有来自第一个级联的c结果将通过复杂排序函数，然后将返回最高k，k≤c的结果给用户。我们的目标是实现第一个级联，尽可能快地运行，而不会显着降低端到端的结果质量。在我们的实现中，我们允许不安全的提前终止技术，也就是说，我们给CF的c结果可能不同于使用SF进行穷尽的top-c计算所得到的结果。

我们用两种方法衡量质量：
（i）重叠@（k，c），这意味着通过彻底应用CF（即ccf =∞或至少相当大）将返回的最多k个结果是多
（ii）NDCG @ k，这是考虑结果顺序的标准化折扣累积收益。

#### 问题讨论
注意，虽然上面的定义只假定了两个级联SF和CF，但只要有任何附加中间级联在CF近似方面做得不错，即不会损失太多的好结果由SF提名进一步处理。我们相信在实践中这是一个合理的假设，并假设将第二级联细分为更多的级联是一个单独的问题。出于同样的原因，所报告的运行时间仅用于第一级联，因为第二级联的成本应该仅取决于c。

尽管第一级联的不安全实现原则上可以比使用SF的安全析取或连接顶级c计算获得更好的质量，但这并不是真正的预期。因此，我们的目标是做（几乎）以及这两个选择，在[3，5]中显示出好，而比这些和其他非安全的竞争者要快得多。


### 3.2 总体方法
我们现在描述我们的方法，该方法从可用于使用SF运行查询的集合的现有倒排索引开始。然后，我们创建额外的辅助索引结构，以快速找出有前途的候选人我们创建两种结构，单项结构和术语对，或者两两结构，它们共同组成第一层索引，而完全倒排索引1构成第二层。对于第一层中的单项结构，我们为每个倒排列表选择一些高分的帖子，并按降序排列。配对结构是通过交叉两个倒排列表得到的，并保留一定数量的高分两阶段过帐，其中这个过帐的分数是两个构成过帐的影响分数的总和。这些结构也按影响分数的降序排列。我们稍后将讨论如何根据查询跟踪和影响分数来选择将哪些帖子放入第一个图层。

当查询进入时，现在通过首先选择并访问索引第一层中小得多的相关结构的前缀来执行第一级联。之后，我们对第二层进行有限数量的查找，以获得一些有前途的文档的额外分数，我们在第一层中找到了部分分数。最后，我们确定c文件供CF进一步评估。我们展示了图1中的整体索引结构，其中查询“dog cat mouse”被处理。

对于我们的问题设置，有各种技术问题需要解决。特别是在构建第一层的时候，我们需要确定构建单项结构的深度，以及对于哪些项我们应该建立一个成对的结构，以及深度。目标是要使结构足够深，以找到最好的结果，但不要太深，以至于整体指数的大小会大幅增加。当一个查询进入时，我们需要决定哪一个可用的索引结构可以查询到什么深度 —— 总是使用第一层中所有可能相关的结构直到它们的全部深度都不是有效的。我们还需要决定对第二层进行什么样的查找，以确定要提交给复杂排序器以进行全面评估的c结果。我们后来提出并评估所有这些问题的解决方案。

总的来说，我们的方法有以下步骤需要执行。在建立索引过程中，我们有两个步骤：

- 建模：
我们通过对有限大小的查询轨迹执行训练来构建两种类型的模型：
（a）查询的语言模型，使我们能够预测某些术语和术语组合
（b）质量模型，将第一层结构中的发布的排名与其在CF下的最高结果的可能性相关联。
- 索引建立：
我们根据构建的模型构建第一层，通过仔细选择要构建的结构和深度，以最大的空间预算为准。

后来，当一个查询进入系统时，我们执行下面的一系列步骤：

- 在线贪婪深度选择：我们考虑相关结构的列表，并根据质量模型和决定哪些应该访问哪些深度基于一个简单的模型来查询处理成本。实际上，成本将根据第一层结构中的总访问深度以及第二层中的查找数量来建模，并有一定的预算用于查询。 
- 查询处理：我们将访问的结构及其对应的访问深度（如上一步所选）放入简单但快速的内存查询处理器中。 
- 第二层查找：我们决定为哪个候选文档进行第二层查找，以获得更精确的分数。 
- 最终选择：我们选择应该由复杂排序器评估的c结果。


### 3.3 索引构建

我们现在更详细地描述索引构建中的两个步骤。首先建立两个模型，一个用于查询和查询词分布，另一个用于模拟索引结构不同部分的质量贡献。然后将这些模型存储起来，以便在建立索引和查询处理时使用。

#### 建模
对于第一个模型，我们使用标准的语言建模工具，特别是基于Kneser-Ney平滑的MIT语言建模（MITLM）工具包2。我们在查询轨迹的一部分（与评估中使用的任何查询不同）训练这些模型，以获得两个概率p（t）的估计值，t是随机传入查询中词条t出现的概率，p（t1， t2），在这样的查询中出现t1和t2的概率。我们将这些称为查询语言模型。

对于第二个模型，给定一个在列表中具有等级r（即，在其列表中具有第r个最高影响分数）的词语t的发布p，我们想要粗略估计该发布属于给定包含t的随机查询，在复杂排序器CF下的top-k结果。这是通过发出训练查询来完成的，并且对于查询词列表之一中的每个发布，存储其排名，其倒排列表的长度，以及它是否是查询的前k个结果的一部分。我们将列表长度和列表内的相对等级分成几十个范围（类别）。然后，我们将我们的数据聚合成一个二维表A，其中A [i，j]估计属于列表长度等级i和相对等级等级j（其可能对应于列表长度在1000和1000之间的概率） 1500和120和160之间的排名）导致前k结果。这种方法提供了足够准确的预测，同时允许在索引建立和查询处理期间进行极快的查找以获得对p（top-k | t）的估计，发布是top-k结果的一部分，因为其词项t是查询的一部分。

然后我们重复词项交叉的过程，在这里我们创建一个表格，在t1和t2两个交集中的每个发布中，我们使用交集的长度和发布在交集中的排名来估计p（ top-k | t1，t2），如果在查询中出现t1和t2，则成对发布是top-k结果的一部分的可能性。我们将这些模型用于单个列表和词项交集作为过帐质量模型。


#### 索引建立
给定一个空间预算，我们的下一个目标是建立第一层，包含可能导致在随机查询下的top-k结果的词项和词项对的提交。为此，我们将单独的空间预算分配给第一层中的singleterm和pairwise结构。对于单项列表，我们贪婪地挑选倒排列表中最高级别的帖子以添加到第一层。也就是说，我们尝试选择p（t）·p（top-k | t）的最高值的发帖。由于我们基于模型的这个值的估计在每个列表中预计是一个单调减少的阶梯函数，所以我们可以通过增加排序来对每个列表进行排序，并从列表的开头选择具有相同值的张贴块，直到预算为止用尽了堆决定从哪个列表中选择。

我们重复这个贪婪的选择过程，以配对发布。由于存在大量的项对，我们首先通过只考虑项t1和t2的交点来限制空间，对于一些小的θ，p（t1，t2）≥θ。然后这些交叉点被创建并按照影响进行排序，并且基于我们对p（t1，t2）·p（top-k | t1，t2）的估计，我们再次从交叉点开始选择大量的发布，直到预算用尽。

第一层的所有结构都保持从最高到最低的影响分数排序。单期发布的格式是（docID，impact），而词项对发布布局是（docID，impactt1，impactt2）。请注意，对于单期结构，我们不会从第二层删除第一层中的张贴，而是创建张贴的副本，因此会使用额外的空间。原因是我们只能访问有限数量的第一层结构，因此我们需要确保对第二层的查找可以检索所有的帖子。一个例外是非常短的列表，其长度小于100，我们总是将整个列表移动到第一层，并在包含该术语的任何查询中完全访问它。因此，这些列表不会增加空间使用量（虽然它们的整体规模很小）。我们还添加了一个额外的规则，将任何选定的单项和双元结构的深度限制为查询的最大访问深度，通常为几千个帖子，因为任何超出访问深度的帖子都不会被使用。


### 3.4 查询过程

我们现在描述查询处理中涉及的步骤：在线贪婪深度选择，查询处理器，第二层查找以及最终的候选选择。

#### 在线贪婪深度选择
给出查询，我们首先确定第一层中可用的所有相关结构。这通常包括查询的所有单项结构，因为我们的语言模型为所有项分配非零概率，并且第一个贴子往往具有非常高的p（top-k | t）值，特别是对于短列表。只有一些配对结构通常可用于查询。对于每个查询，我们都有一个成本预算来确定我们可以访问多少相关结构。例如，我们可能有一个预算b = 1000，这意味着我们只能从结构中访问总共b个帖子。然后，对于每个结构，我们选择一个（可能是空的）帖子的前缀。除了我们根据p（top-k | t）和p（top-k | t1，t2）分别选择大量的帖子，而不用乘以p（t ）和p（t1，t2）（因为在这一点上查询已经包含了这些术语）。我们注意到，我们可以对这种方法进行各种改进，通过为成对和单期发布收取不同的成本，或者根据查询的难度分配不同的预算。

#### 查询处理器
我们现在在选定的结构和相应的深度上运行一个快速简单的查询处理器。这个处理器将第一层结构的选定前缀复制到一个数组中，然后运行一个快速的基数排序（Radix Sort），以docID对排序进行排序。随后的扫描然后聚合每个docID的影响分数，并为每个docID创建一个位过滤器，说明哪些词项可能需要查找到第二层。在扫描过程中，我们还会筛选冗余查找，如下所示：假设在“cat”列表的前缀中找到了docID为7，影响为2.9的帖子，并且我们还访问了“cat dog”对的所有配对帖子，得分2.1或更高。然后，我们不必查看第二层docID 7中的“dog”列表 —— 如果存在这样的发布，我们会将其视为成对发布的一部分。

我们最初实现了一个使用哈希表累加器的TAAT查询处理器。但是，我们发现基于排序的方法要快得多，速度是2到3倍。这样的基于排序的方法是可能的，因为我们在查询开始时修复了每个结构的访问深度。

#### 第二层查找和最终候选人选择

接下来，我们检查候选人和他们的累计得分，其中大部分得分是部分的，而且许多人可能只是查询其中一个查询项。我们现在决定对这些候选人中的哪一个进行第二层的查找来完成他们的分数，但要根据查询数量（比如每个查询几千）进行预算。这是使用累积的部分分数完成的，因为这提供了相关性的强烈信号。我们通过运行一个随机的近似选择算法来选择部分得分最高的候选人，我们首先绘制一个影响分数的样本，对这个样本进行排序，从样本中选择一个合适的阈值，然后保持所有影响高于这个分数的候选人。最后，我们对这些候选人进行所有必要的查找到第二层，并将具有最高完成BM25得分的c候选人提交给CF.


## 4 实验设置

在本节中，我们将描述数据集，排名模型，评估指标以及实验设置。
数据集：我们所有的实验都是在ClueWeb09B集合上进行的，集合包括50,220,423个文档，86,532,822个不同的词项和170亿个帖子。为了评估，我们使用了TREC 2009 Million Query Track（40k），我们称之为Million09。我们的建模步骤的训练集包括从Million09随机选择的30k个查询，而性能评估测试集包含剩余的10k个查询中的3k个查询。表1显示了测试查询集的查询长度。

TREC 2010到2012 Web Track主题（150）被用于培训机器学习的复杂排名CF.对于语言模型，我们使用麻省理工学院语言建模（MITLM）工具包，对随机选取的150万个文档样本，使用模型的线性插值对查询集合进行训练查询。

#### 排名模型
我们选择BM25排名方案作为我们的第一排名，因为它被广泛用作文献中的简单排序器，并且满足期望的性质，既快速计算又提供合理的初始候选集合。

最近的研究[31,51]表明，使用具有数十或数百个特征的学习 —— 排序方法获得的排名方案在质量方面优于传统的词袋模型。有一些可用的学习排名工具。我们决定使用LambdaMart [53]来学习我们的复杂排名CF，因为它被认为是最有效的学习到排名模型[22,35]之一。我们根据文献[5,36,49]的标准特征对TREC2010至2012年的150个查询进行了培训。表2列出了这些功能的一个子集。锚文本功能是从[18]中提取的数据，而垃圾邮件和pagerank值是从[16]。分布特征指的是当文档被分割成固定大小（比如说100个词）的片段时，词项出现在特定文档中的分散。

#### 评估指标
可扩展网页搜索体系结构设计的主要方面包括质量，时间和空间。因此，我们对这三个方面提出的框架进行了评估。我们使用Overlap @（k，c）和NDCG @ k度量所提出方法的端到端质量。具体而言，级联分级器设置内的端到端有效性评估如下进行。在第一个级联中，top-c文档是基于我们的方法获得的，然后在第二个级联中，将CF应用于这些文档以返回最终的top-k。

对于第一个级联的有效性，我们将Overlap @（k，c）作为将CF应用于安全析取BM25的所有最高2000年结果时得到的top-k文档的一部分进行度量，我们的算法。虽然将复杂排序器应用于查询词汇联合中的所有文档是不可行的，但是我们在初步实验中发现，除2000以外，最终的top-k几乎没有变化。这一选择也直接得到了[35]中的建议的支持。因此，对于查询而言，1.0的重叠意味着在我们的方法的c个候选中找到所有top-k结果。除非另有说明，我们使用k = 10。

我们使用平均查询延迟（以毫秒为单位）来评估我们方法的速度以生成候选项。也就是说，我们测量查询到达的时间，直到顶级候选项准备好由CF来评估的时间。 （我们没有计算应用CF的时间，因为它对于所有方法都是一样的。）空间开销被测量为基线完整索引的百分比。

#### 索引
第二层使用[55]中提出的PForDelta [59]版本进行索引和压缩。算法使用C ++实现，并使用gcc和-O3优化进行编译。实验是在2.27Ghz Intel Xeon（E5520）CPU的单核上进行的。所有的数据结构和索引都是内存驻留。

#### 参数
总的来说，所提出的框架使用以下参数：
（a）访问成本预算，即每个查询访问的张贴数量，
（b）执行查询的文档数量，
（c）候选数量 c
（d）空间预算，即超出标准指数的额外空间数量。
在选择第一层中的词对结构的过程中，我们只考虑Million09查询跟踪的概率（根据MITLM的语言模型）至少为1.99 * 10-16。接下来，我们基于这些参数提出我们方法的实验评估。

## 5 实验评估

在本节中，我们将从有效性，效率和空间的角度对我们的方法进行实验评估。

### 5.1 没有空间约束

在第一个实验中，我们在假设没有空间预算的情况下评估候选生成算法;即在查询时可用的所有可能的第一层单项和成对结构。虽然这种情况是不现实的，但由于成对结构的空间开销可能非常大，这表明了所提出方法的潜力。

我们将我们的方法与一个naeïve基线进行比较，给定一个成本预算b，在相同的深度访问第一个层的所有相关结构。因此，如果特定查询有5个可用结构，且成本预算为5k个过帐，则基准线将访问每个结构中的前1k个过帐。请注意，这种方法类似于[48]中提出的固定方法。我们评估三种版本的这种方法，对于只有单项，只有两两类型的结构可用的情况，才能表明两种类型的结构都有好处。此外，我们实现了一个透视选择算法，知道第一层的帖子中的哪个docID导致top-k结果，然后以最优的方式选择结构的前缀，从而给出质量的上限可以通过影响排序结构上的任何深度受限的访问方案来实现。这个算法被包括来观察我们的算法有多接近最优。

#### 设置
我们假设无限的空间预算，并使用以下参数设置和选择策略：c是500，算法彻底执行对第一层结构访问中看到的所有docID的查找（因此，查找的数量仅受访问深度），并且根据最高BM25选择c个候选者。

#### 有效性
图2显示了重叠（500,10），即在c = 500个候选者中保留的正确的前10个结果的分数，因为访问成本预算从500变化到20000，并且第一层由不同的结构。很明显，透视算法对于所有的访问预算都达到了最好的质量，因为它是我们方法的一个上限。另一方面，我们观察到，对于naÄêve方法，只有成对结构一直胜过只有一个单项，但都达到了最好的质量，当成本预算是2000时为0.8864。贪婪选择算法性能优于所有最新的方法，即使在适度的访问预算下也能达到最佳的透视效果。例如，2000年访问预算的质量是0.946。因此，相同的前10名结果中超过94％被返回。最后，随着成本预算的增加，所有算法的质量都会提高，因为我们考虑更多的发布作为候选。尤其是，贪婪达到5000的访问预算真正接近千里眼的质量。

#### 效率
在表3中，当访问预算从500到20000变化时，我们报告贪婪算法的平均查询处​​理时间（以毫秒为单位）。我们观察到，在无限制查找的情况下，访问预算是查询处理时间的非常好的代理，所以我们只报告贪婪的时间;具有相同访问预算的na¨Íve和clairvoyant算法的数字非常相似。根据表3，我们可以看到在访问预算2000年可以在0.51ms内达到接近0.946的重叠。随着访问预算的增加，查询处理变得更慢，因为我们处理更多的发布。因此，在没有空间限制的情况下，质量和速度都非常好。接下来，我们评估是否可以用有限的空间获得可比的数字。

### 5.2 有空间限制

在下一个实验中，我们放弃了无限空间预算的假设，并把重点放在更现实的情景上。更具体地说，我们在整个第二层索引上允许第一层结构的特定空间开销百分比。给定不同的空间预算，我们评估贪婪算法的质量和速度。在这个实验中，我们使用前面的实验的设置和参数，并假设第一层包含单项和双项结构。我们仍然执行所有查找来完成第一层中所有docID的部分分数。

#### 有效性
在表4中，当第一层结构允许空间开销的特定百分比，并且访问成本预算为2000和5000时，我们介绍了贪婪算法（通过Overlap @（500,10）测量）的有效性。对于单期结构，我们决定每个清单最多可以发布2000个和5000个帖子，分别相当于完整索引的7.1％和9.9％。在这个小的固定空间开销之上，我们有一个有限的空间预算，用于按照贪婪分配算法分配的成对结构。表4中报告的空间仅包括第一层中的成对结构。首先，我们观察到，即使在有限的空间预算下，我们提出的方法也能很好地工作，而且质量损失适中（我们稍后会看到NDCG数字。）除非有大量空间可用，否则将成对结构的空间预算增加到50％以上似乎不能提供显着的质量提高。当访问成本更大时，考虑到考虑更多的候选者，质量也会更好。考虑到我们实现的显着的性能提升，2000年访问预算的空间开销为57.1％（单一7.1％，50％对），5000年为59.9％。例如，在Maguro系统[42]中，20倍的指数规模增长对于3倍的性能改进是合理的。

#### 效率
表5显示了当访问预算为2000或5000时，贪婪算法对各种空间预算的平均查询处​​理时间。如前所述，访问预算为性能提供了可靠的代理，这在表5中很明显。贪婪算法平均需要0.551ms和1.055ms，对于2000和5000的访问预算，分别仍然没有查找限制。随着空间预算的增加，两种访问预算的性能都会变好。原因是在成对的结构中出现了更多的高质量的帖子，这导致更少的查找条件。

### 5.3 查找选择策略
在前面的实验中，所有的算法在第二层彻底地执行查找。但是，我们将会看到，查找选择策略在性能中起着重要的作用。因此，我们现在看看更好的查找策略。

首先，我们调查查询处理成本如何分配。表6显示5000个访问预算和3000个查找的查询处理成本的每个部分的平均时间开销。回想一下，查询处理包括在线贪婪深度选择，基数排序，用于聚合分数和查找修剪的扫描，通过采样选择，查找到第二层以及用于获得候选c的另一选择。从表6可以看出，查找占总成本的很大一部分，因为它涉及到解压缩和访问许多随机块。

我们没有彻底地执行所有查找，而是根据部分BM25得分，只保留一定数量的候选查询。要做到这一点，我们执行一个随机的近似选择，如前所述。我们评估了2000年和5000年的访问预算查找策略的质量和速度，以及在每个访问预算的单一期限结构之上的0.5个成对空间预算。图3显示了在两个访问预算下，Overlap @（500,10）和几个m查找配置的平均查询处​​理时间。更具体地说，我们允许针对访问预算5000查找{500,1k，2k，3k，5k}候选，并且针对访问预算2000（从左到右）查找{500,750,1k，1.5k，2k}。我们看到，使用所提出的查找方法可以以一些质量损失为代价来获得更好的性能，因此在质量和时间之间有一个折衷。


接下来，我们比较我们的方法与其他最近发表的方法的速度。虽然前10个查询处理可以在几毫秒内完成[19]，但选择前500个对于大多数方法来说要昂贵得多。表7列出了不同的前500名候选人生成方法的运行时间。我们用C++实现了所有的方法，并在ClueWeb09B数据集上运行它们。为了安全的方法，我们从[19]中选择最快的分离方法BMW-LB，和[21]中最快的连接方法BMA。对于不安全的方法，我们实现了[52]中的最佳方法，这是基于树的优先级与修剪，最好的方法[43]，BMWCS，使用10％的索引作为第一层。我们用5k-3k设置的方法要快得多，因为它只计算最多5k个帖子，这意味着每个查询的文档少于5k，而其他方法通常评估更多的文档。我们的在线和离线发布选择机制都对其良好的表现作出了重大贡献。 BMA拥有第二快的速度，因为它是一个连接算法，只评估有限数量的文档。BMW-CS在第一层执行BWM，根据冲击评分，这是全部指数的前10％。 BMW-CS与我们的方法不同，因为除了第一层中的单体之外，我们还使用配对结构，而且他们没有每个查​​询的固定访问预算或贪婪深度选择技术。他们的速度比我们的要慢很多，但比BMWLB还要快。优先级比BMW-LB慢，前500名。对于空间开销，BMA和BMW-CS都使用小于指数大小的5％来存储最大区块指数。 BMW-CS的两层不相交，所以第一层不占用额外的空间。 BMW-LB需要25％的时间来缓存LB指数，而优先级则不需要额外的空间。我们用5k-3k设置的方法需要59.9％的额外空间。请注意，商业搜索引擎通常愿意接受相当小的速度提高空间开销[42]。

我们现在评估我们的方法的有效性。表8显示了所有方法的Overlap @（500,10），以及三种不同设置的方法。 BMW-LB的效果最好，BMA几乎一样好，但稍差。这意味着联合查询处理在质量方面几乎与分离性一样好，这也在[5]中显示。在表9中，我们根据复杂排序器重新排列了所有方法的结果。 BMW-LB + CF比BMW-LB要好得多，这意味着复杂的排序器在识别更多相关结果方面表现良好。 5k-3k的设置在我们的方法中在所有的截断水平上都能保持最好的质量，对于Overlap和NDCG，它也比其他两种不安全的方法略好一些。总的来说，我们看到，在NDCG下，我们的方法可以在不到一毫秒的时间内快速识别几乎与安全分离方法（BMW-LB）一样好的结果。

### 5.4 改变查询长度和候选者

接下来，我们使用我们的方法的各种配置来测试查询长度对速度和质量的影响。表10给出了改变查询长度时的平均查询处​​理时间（ms），而表11报告了每个配置的对应重叠（500,10）。随着查询长度的增加，查询处理时间也增加，因为执行更多结构的更多查询。另一方面，质量下降，因为较长的查询中的顶部结果往往会在影响的列表中更深（在Fagin对其算法的理论分析中显示的top-k查询处理中的基本事实[23]）。


表12显示了我们的候选人生成算法（cutoff c）对5000-3000设置的Overlap @（c，10）返回的候选人数量的影响。随着截断值c的增加，质量增加，直到500左右变平。这证明我们在整篇论文中选择了c = 500。

## 6.结论和未来的工作

在本文中，我们提出了一种快速的第一阶段候选生成方法级联排名架构。我们的框架基于查询词频率和发布质量建立了索引结构的辅助层（单项和成对结构），然后基于成本预算和使用提前终止技术在查询时选择性地访问。实验评估表明，所提出的框架可以比联合或分离的top-k计算更快地找到候选数量级，质量损失很小。

未来的工作包括增加专门的短语结构和接近我们的框架。我们还希望通过进一步优化查询处理器和查找机制，例如通过添加位矢量或者如[4]中的布隆过滤器，或者使用更复杂的规则来决定执行哪些查找（可能基于类似的想法到[52]）。
